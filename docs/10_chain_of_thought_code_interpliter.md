#### 全体共通
| # | タスク                                                                                                                | 目的                          |
| - | ------------------------------------------------------------------------------------------------------------------ | --------------------------- |
| 1 | Python 3.10+ 仮想環境を作成し、必要なライブラリ（openai, pandas, numpy, matplotlib, pytesseract, pillow, reportlab, boto3 など）をインストール | 各シナリオで必要な依存ライブラリを一元管理するため   |
| 2 | OpenAI API キーを `.env` に保存し、`python-dotenv` で読み込む                                                                   | キーをハードコードしないベストプラクティス       |
| 3 | 共通ユーティリティ（例：`tools.py`）に、Code Interpreter 用ヘルパ、CoT 用プロンプトテンプレート、画像アップロード／S3 ダウンロード関数を実装                            | 再利用性を高め、サンプルがシンプルになるよう分離設計  |
| 4 | 「思考→コード→観察→思考」ログを書き出すロガーを用意                                                                                        | CoT の透明性を担保し、後学習用データにも流用可能  |
| 5 | GitHub リポジトリを作成し、Jupyter Notebook と `.py` 版の両方を配置                                                                  | 実行例とライブラリ呼び出し例を併記して学習効果を高める |
| 6 | プロンプトテンプレートの整備：Chain of Thought の一貫性を保つため、各ステップのプロンプトテンプレートを整備し、再利用可能な形で管理                                         | 一貫性のあるプロンプト設計を実現            |
| 7 | エラーハンドリングの強化：各シナリオで発生しうるエラー（例：API 呼び出し失敗、OCR 誤認識、S3 アクセスエラーなど）に対するハンドリングを実装                                        | 堅牢性を向上させるため                 |
| 8 | テストケースの追加：各シナリオに対して、異なるパラメータや入力データを用いたテストケースを追加し、モデル挙動の再現性を検証                                                      | モデルの信頼性と再現性を確保              |

### （1）ファイナンス - リスクシミュレーション
データソース: Yahoo Finance API（yfinance ライブラリ）を使用して、特定銘柄の過去株価データを取得します。
例: yfinance.download("AAPL", start="2020-01-01", end="2023-01-01")
注意点: データの取得期間や頻度（例：日次、週次）を適切に設定し、分析目的に合致したデータを収集します。

#### ファイナンス ― VaR モンテカルロ
| # | タスク                                                                                                 | 詳細                                                                    |
| - | --------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| 1 | データ取得関数：Yahoo Finance API（`yfinance` ライブラリ）を使用して、特定銘柄の過去株価データを取得                                    | 例: `yfinance.download("AAPL", start="2020-01-01", end="2023-01-01")`  |
| 2 | CoT プロンプト：「①価格取得\n②対数収益率計算\n③正規分布にフィット\n④numpy.random.normal で 10,000 シナリオ生成\n⑤95% 分位＝VaR 抽出」と文章で列挙 | モデルに手順を説明させ、透明性を確保                                                    |
| 3 | Code Interpreter 呼び出し：上記手順を Python で自動実行し、ヒストグラム PNG を保存                                            | 計算負荷を AI 側に委譲し、可視化を添付                                                 |
| 4 | 最終メッセージでヒストグラムを解釈し、「VaR は −X %」と記述                                                                  | “結果の再解釈” フェーズ                                                         |
| 5 | テストケース：銘柄・期間を変えて3ケース実行し、数値の妥当性を確認                                                                   | モデル挙動の再現性を検証                                                          |

### （2）画像理解＋データ抽出
データソース: COCO-Text データセットなど、公開されている棒グラフ画像データセットを使用します。
代替データ: ChartOCR フレームワークを使用して、合成された棒グラフ画像を生成し、OCR 処理のテストに利用します。
注意点: OCR 処理の精度を向上させるため、画像の解像度や前処理（例：グレースケール変換、ノイズ除去）を適切に行います。

#### 画像理解＋データ抽出
| # | タスク                                                                                           | 詳細                  |
| - | --------------------------------------------------------------------------------------------- | ------------------- |
| 1 | サンプル棒グラフ画像（JPEG/PNG）を `data/` 配下に用意                                                           | OCR 処理対象の素材         |
| 2 | CoT プロンプト：「①画像ロード\n②バー領域切り出し\n③pytesseract で数値抽出\n④pandas DataFrame 化\n⑤平均・最大値など統計→洞察まとめ」を文章化 | ステップを明示             |
| 3 | Code Interpreter：Pillow で前処理し、pytesseract で OCR、DataFrame 生成 → CSV & プレビュー画像返却                | データ化を自動化し、人手レス運用を実現 |
| 4 | 最終メッセージで抽出結果テーブルを要約し、「前年比＋12 %成長」など洞察を述べる                                                     | 再解釈フェーズ             |
| 5 | 失敗時ハンドリング：OCR 信頼度 < 85 % なら再スキャンまたは手動補正を促す                                                    | 実運用での堅牢性を確保         |

### （3）ETL & レポート自動生成
データソース: AWS Cost and Usage Report（CUR）を使用して、日次の KPI データを取得します。
代替データ: Finout の S3 テレメトリ統合を使用して、日次の CSV データを生成し、S3 バケットに保存します。
注意点: データの整形や欠損値処理を適切に行い、PDF レポートの生成に適した形式に変換します。

####  ETL & PDF レポート自動生成
| # | タスク                                                                          | 詳細               |
| - | ---------------------------------------------------------------------------- | ---------------- |
| 1 | S3 から日次 CSV 取得：boto3 でバケット接続、最新ファイルをダウンロード                                   | データロード段階         |
| 2 | CoT プロンプト：「①欠損補完\n②型変換\n③日別 KPI 計算\n④reportlab で PDF 作成\n⑤メール送信 API 呼び出し」を宣言 | ETL→報告→配信 まで一気通貫 |
| 3 | Code Interpreter：pandas で ETL、reportlab で PDF 報告書作成、S3 へ再アップロード              | 計算＆レポート生成を自動化    |
| 4 | Function Calling で send\_email エンドポイントを呼び出し、PDF リンクを送信                       | 完全自動化を実現         |
| 5 | スケジューラ（cron または GitHub Actions）を設定し、毎朝 8 時 JST に実行                           | 運用フェーズ           |
| 6 | モニタリング：失敗ログを Slack Webhook へ通知                                               | 障害時の即時対応を可能にする   |


